{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "CPython 3.5.5\n",
      "IPython 6.3.0\n",
      "\n",
      "numpy 1.14.2\n",
      "scipy 1.0.1\n",
      "matplotlib 2.2.2\n",
      "tensorflow 1.7.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,scipy,matplotlib,tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9장 – 텐서플로 시작하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_이 노트북은 9장에 있는 모든 샘플 코드와 연습문제 해답을 가지고 있습니다._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬 2와 3을 모두 지원합니다. 공통 모듈을 임포트하고 맷플롯립 그림이 노트북 안에 포함되도록 설정하고 생성한 그림을 저장하기 위한 함수를 준비합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 2와 파이썬 3 지원\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# 공통\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# 맷플롯립 설정\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"tensorflow\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 계산 그래프 만들고 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())  # 10\n",
    "    print(z.eval())  # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)  # 10\n",
    "    print(z_val)  # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규방정식을 사용해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7185181e+01],\n",
       "       [ 4.3633747e-01],\n",
       "       [ 9.3952334e-03],\n",
       "       [-1.0711310e-01],\n",
       "       [ 6.4479220e-01],\n",
       "       [-4.0338000e-06],\n",
       "       [-3.7813708e-03],\n",
       "       [-4.2348403e-01],\n",
       "       [-4.3721911e-01]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "넘파이와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69419202e+01]\n",
      " [ 4.36693293e-01]\n",
      " [ 9.43577803e-03]\n",
      " [-1.07322041e-01]\n",
      " [ 6.45065694e-01]\n",
      " [-3.97638942e-06]\n",
      " [-3.78654265e-03]\n",
      " [-4.21314378e-01]\n",
      " [-4.34513755e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 경사 하강법을 사용해서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사 하강법은 먼저 특성 벡터의 스케일을 조정해야 합니다. 텐서플로를 사용해 할 수 있지만 그냥 여기서는 사이킷런을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
      " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
      " -8.52651283e-15]\n",
      "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
      "  0.01359031]\n",
      "0.11111111111111005\n",
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
    "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
    "print(scaled_housing_data_plus_bias.mean())\n",
    "print(scaled_housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수동으로 그래디언트 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0 MSE = 9.161542\n",
      "에포크 100 MSE = 0.7145004\n",
      "에포크 200 MSE = 0.56670487\n",
      "에포크 300 MSE = 0.5555718\n",
      "에포크 400 MSE = 0.5488112\n",
      "에포크 500 MSE = 0.5436363\n",
      "에포크 600 MSE = 0.5396291\n",
      "에포크 700 MSE = 0.5365092\n",
      "에포크 800 MSE = 0.53406775\n",
      "에포크 900 MSE = 0.5321473\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685523 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401656],\n",
       "       [-0.34770882],\n",
       "       [ 0.36178368],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.6614529 ],\n",
       "       [-0.6375279 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동미분 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gradients = ...` 라인만 빼고 위와 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(mse, [theta])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0 MSE = 9.161542\n",
      "에포크 100 MSE = 0.71450037\n",
      "에포크 200 MSE = 0.56670487\n",
      "에포크 300 MSE = 0.5555718\n",
      "에포크 400 MSE = 0.54881126\n",
      "에포크 500 MSE = 0.5436363\n",
      "에포크 600 MSE = 0.53962916\n",
      "에포크 700 MSE = 0.5365092\n",
      "에포크 800 MSE = 0.53406775\n",
      "에포크 900 MSE = 0.5321473\n",
      "best_theta:\n",
      "[[ 2.0685523 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401656]\n",
      " [-0.3477088 ]\n",
      " [ 0.36178365]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.66145283]\n",
      " [-0.6375278 ]]\n"
     ]
    }
   ],
   "source": [
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"best_theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`a`와 `b`에 대한 다음 함수의 편도함수를 어떻게 구할 수 있나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21253923284754914"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "a = tf.Variable(0.2, name=\"a\")\n",
    "b = tf.Variable(0.3, name=\"b\")\n",
    "z = tf.constant(0.0, name=\"z0\")\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "\n",
    "grads = tf.gradients(z, [a, b])\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a=0.2$와 $b=0.3$일 때 함수 값을 계산하고 그 다음 $a$와 $b$에 대한 편미분을 구합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21253741\n",
      "[-1.1388495, 0.19671397]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(z.eval())\n",
    "    print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GradientDescentOptimizer` 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0 MSE = 9.161542\n",
      "에포크 100 MSE = 0.7145004\n",
      "에포크 200 MSE = 0.56670487\n",
      "에포크 300 MSE = 0.5555718\n",
      "에포크 400 MSE = 0.54881126\n",
      "에포크 500 MSE = 0.5436363\n",
      "에포크 600 MSE = 0.53962916\n",
      "에포크 700 MSE = 0.5365092\n",
      "에포크 800 MSE = 0.53406775\n",
      "에포크 900 MSE = 0.5321473\n",
      "best_theta:\n",
      "[[ 2.0685523 ]\n",
      " [ 0.8874027 ]\n",
      " [ 0.14401656]\n",
      " [-0.3477088 ]\n",
      " [ 0.36178365]\n",
      " [ 0.00393811]\n",
      " [-0.04269556]\n",
      " [-0.66145283]\n",
      " [-0.6375278 ]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"best_theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모멘텀 옵티마이저 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_theta:\n",
      "[[ 2.068558  ]\n",
      " [ 0.82962847]\n",
      " [ 0.11875335]\n",
      " [-0.26554456]\n",
      " [ 0.3057109 ]\n",
      " [-0.00450249]\n",
      " [-0.03932662]\n",
      " [-0.8998645 ]\n",
      " [-0.8705207 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"best_theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 훈련 알고리즘에 데이터 주입하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 플레이스홀더 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n",
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미니배치 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255152],\n",
       "       [-0.31211877],\n",
       "       [ 0.38510376],\n",
       "       [ 0.00434168],\n",
       "       [-0.0123295 ],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델의 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 0 MSE = 9.161542\n",
      "에포크 100 MSE = 0.7145004\n",
      "에포크 200 MSE = 0.56670487\n",
      "에포크 300 MSE = 0.5555718\n",
      "에포크 400 MSE = 0.54881126\n",
      "에포크 500 MSE = 0.5436363\n",
      "에포크 600 MSE = 0.53962916\n",
      "에포크 700 MSE = 0.5365092\n",
      "에포크 800 MSE = 0.53406775\n",
      "에포크 900 MSE = 0.5321473\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_epochs = 1000                                                                       # 책에는 없습니다.\n",
    "learning_rate = 0.01                                                                  # 책에는 없습니다.\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            # 책에는 없습니다.\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            # 책에는 없습니다.\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")                                      # 책에는 없습니다.\n",
    "error = y_pred - y                                                                    # 책에는 없습니다.\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    # 책에는 없습니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)            # 책에는 없습니다.\n",
    "training_op = optimizer.minimize(mse)                                                 # 책에는 없습니다.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크\", epoch, \"MSE =\", mse.eval())                                # 책에는 없습니다.\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0685523 ],\n",
       "       [ 0.8874027 ],\n",
       "       [ 0.14401656],\n",
       "       [-0.3477088 ],\n",
       "       [ 0.36178365],\n",
       "       [ 0.00393811],\n",
       "       [-0.04269556],\n",
       "       [-0.66145283],\n",
       "       [-0.6375278 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval() # 책에는 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`theta`를 `\"weights\"`와 같은 다른 이름으로 저장하고 복원하는 Saver 객체를 원할 경우엔:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({\"weights\": theta})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 Saver 객체는 `.meta` 확장자를 가진 두 번째 파일에 그래프 구조도 저장합니다. `tf.train.import_meta_graph()` 함수를 사용하여 그래프 구조를 복원할 수 있습니다. 이 함수는 저장된 그래프를 기본 그래프로 로드하고 상태(즉, 변수 값)를 복원할 수 있는 `Saver` 객체를 반환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "# 빈 그래프로 시작합니다\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"/tmp/my_model_final.ckpt.meta\")  # 그래프 구조를 로드합니다.\n",
    "theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\") # 책에는 없습니다.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")  # 그래프 상태를 로드합니다.\n",
    "    best_theta_restored = theta.eval() # 책에는 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(best_theta, best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 사용하면 그래프를 만든 파이썬 코드가 없이도 미리 훈련된 모델을 임포트할 수 있습니다. 모델을 저장하고 변경할 때도 매우 편리합니다. 이전에 저장된 모델을 구축한 코드의 버전을 찾지 않아도 로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그래프 시각화\n",
    "## 쥬피터에서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"graph_def에서 큰 상수 값은 제외시킵니다.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"텐서플로 그래프 나타내기\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.3745401188473625&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 9\\n          }\\n        }\\n        tensor_content: &quot;<stripped 743040 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 20640\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        tensor_content: &quot;<stripped 82560 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\t\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;predictions&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;predictions&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mse&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\240P\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/mse_grad/Reshape&quot;\\n  input: &quot;gradients/mse_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 20640.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/mse_grad/Tile&quot;\\n  input: &quot;gradients/mse_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/mse_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;sub&quot;\\n  input: &quot;gradients/Square_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/mse_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/Square_grad/Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/Square_grad/Mul_1&quot;\\n  input: &quot;^gradients/sub_grad/Neg&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/Square_grad/Mul_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/Square_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Neg&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/predictions_grad/MatMul_1&quot;\\n  input: &quot;^gradients/predictions_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/predictions_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_theta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/predictions_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_theta/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^theta/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.3745401188473625&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서보드 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                                                        # 책에는 없습니다.\n",
    "    sess.run(init)                                                                # 책에는 없습니다.\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # 책에는 없습니다.\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()                                                     # 책에는 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0703337 ],\n",
       "       [ 0.8637145 ],\n",
       "       [ 0.12255152],\n",
       "       [-0.31211877],\n",
       "       [ 0.38510376],\n",
       "       [ 0.00434168],\n",
       "       [-0.0123295 ],\n",
       "       [-0.83376896],\n",
       "       [-0.8030471 ]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이름 범위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_theta:\n",
      "[[ 2.0703337 ]\n",
      " [ 0.8637145 ]\n",
      " [ 0.12255152]\n",
      " [-0.31211877]\n",
      " [ 0.38510376]\n",
      " [ 0.00434168]\n",
      " [-0.0123295 ]\n",
      " [-0.83376896]\n",
      " [-0.8030471 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.flush()\n",
    "file_writer.close()\n",
    "print(\"best_theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a_1\n",
      "param/a\n",
      "param_1/a\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "a1 = tf.Variable(0, name=\"a\")      # name == \"a\"\n",
    "a2 = tf.Variable(0, name=\"a\")      # name == \"a_1\"\n",
    "\n",
    "with tf.name_scope(\"param\"):       # name == \"param\"\n",
    "    a3 = tf.Variable(0, name=\"a\")  # name == \"param/a\"\n",
    "\n",
    "with tf.name_scope(\"param\"):       # name == \"param_1\"\n",
    "    a4 = tf.Variable(0, name=\"a\")  # name == \"param_1/a\"\n",
    "\n",
    "for node in (a1, a2, a3, a4):\n",
    "    print(node.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복이 많습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
    "b1 = tf.Variable(0.0, name=\"bias1\")\n",
    "b2 = tf.Variable(0.0, name=\"bias2\")\n",
    "\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
    "\n",
    "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
    "relu2 = tf.maximum(z1, 0., name=\"relu2\")  # Oops, cut&paste error! Did you spot it?\n",
    "\n",
    "output = tf.add(relu1, relu2, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relu() 함수를 사용해 더 나아졌습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "    return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu1\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이름 범주를 사용하면 훨씬 더 낫습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                          # 책에는 없습니다.\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")    # 책에는 없습니다.\n",
    "        b = tf.Variable(0.0, name=\"bias\")                             # 책에는 없습니다.\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                      # 책에는 없습니다.\n",
    "        return tf.maximum(z, 0., name=\"max\")                          # 책에는 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 공유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`threshold` 변수를 공유하는 기본적인 방법은 `relu()` 함수 밖에서 정의한 후 매개변수를 통해 전달하는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X, threshold):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)                        # 책에는 없습니다.\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # 책에는 없습니다.\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # 책에는 없습니다.\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # 책에는 없습니다.\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X, threshold) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        if not hasattr(relu, \"threshold\"):\n",
    "            relu.threshold = tf.Variable(0.0, name=\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1                          # 책에는 없습니다.\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # 책에는 없습니다.\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # 책에는 없습니다.\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # 책에는 없습니다.\n",
    "        return tf.maximum(z, relu.threshold, name=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\", reuse=True):\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"relu\") as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold = tf.get_variable(\"threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\", reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1                          # 책에는 없습니다.\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # 책에는 없습니다.\n",
    "        b = tf.Variable(0.0, name=\"bias\")                           # 책에는 없습니다.\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # 책에는 없습니다.\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu6\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\"):\n",
    "        threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "with tf.variable_scope(\"\", default_name=\"\") as scope:\n",
    "    first_relu = relu(X)     # 공유 변수를 만든 후\n",
    "    scope.reuse_variables()  # 재사용합니다.\n",
    "    relus = [first_relu] + [relu(X) for i in range(4)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu8\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]), 1)                        # 책에는 없습니다.\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # 책에는 없습니다.\n",
    "    b = tf.Variable(0.0, name=\"bias\")                           # 책에는 없습니다.\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # 책에는 없습니다.\n",
    "    return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu9\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: my_scope/x\n",
      "x1: my_scope/x_1\n",
      "x2: my_scope/x_2\n",
      "x3: my_scope/x\n",
      "x4: my_scope_1/x\n",
      "x5: my_scope/x\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.variable_scope(\"my_scope\"):\n",
    "    x0 = tf.get_variable(\"x\", shape=(), initializer=tf.constant_initializer(0.))\n",
    "    x1 = tf.Variable(0., name=\"x\")\n",
    "    x2 = tf.Variable(0., name=\"x\")\n",
    "\n",
    "with tf.variable_scope(\"my_scope\", reuse=True):\n",
    "    x3 = tf.get_variable(\"x\")\n",
    "    x4 = tf.Variable(0., name=\"x\")\n",
    "\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):\n",
    "    x5 = tf.get_variable(\"my_scope/x\")\n",
    "\n",
    "print(\"x0:\", x0.op.name)\n",
    "print(\"x1:\", x1.op.name)\n",
    "print(\"x2:\", x2.op.name)\n",
    "print(\"x3:\", x3.op.name)\n",
    "print(\"x4:\", x4.op.name)\n",
    "print(\"x5:\", x5.op.name)\n",
    "print(x0 is x3 and x3 is x5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 `variable_scope()` 블럭은 이름이 `my_scope/x`인 공유 변수 `x0`를 만듭니다. 공유 변수 이외의 모든 연산에 대해서는 (공유되지 않는 변수를 포함하여) 변수 범위가 일반적인 이름 범위처럼 작동합니다. 그래서 두 변수 `x1`과 `x2`에 접두사 `my_scope/`가 붙습니다. 하지만 텐서플로는 이름을 고유하게 만들기 위해 `my_scope/x_1`, `my_scope/x_2`처럼 인덱스를 추가시킵니다.\n",
    "\n",
    "두 번째 `variable_scope()` 블럭은 `my_scope` 범위에 있는 공유 변수를 재사용합니다. 그래서 `x0 is x3`가 참입니다. 여기에서도 공유 변수를 제외한 모든 연산은 이름 범주와 같이 작동합니다. 첫 번째 블럭과 다르기 때문에 텐서플로가 고유한 범주 이름을 만듭니다(`my_scope_1`). 변수 `x4`의 이름은 `my_scope_1/x`가 됩니다.\n",
    "\n",
    "세 번째 블럭은 공유 변수 `my_scope/x`를 다루는 다른 방식을 보여 줍니다. 루트 범위(이름이 빈 문자열입니다)에서 `variable_scope()`를 만들고 공유 변수의 전체 이름(즉, `\"my_scope/x\"`)으로 `get_variable()`을 호출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'Do' b'you' b'want' b'some' b'caf\\xc3\\xa9?']\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "text = np.array(\"Do you want some café?\".split())\n",
    "text_tensor = tf.constant(text)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(text_tensor.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자작 계산 그래프 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x,y) = ((x) * (x)) * (y) + y + 2\n",
      "f(3,4) = 42\n"
     ]
    }
   ],
   "source": [
    "class Const(object):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class Var(object):\n",
    "    def __init__(self, init_value, name):\n",
    "        self.value = init_value\n",
    "        self.name = name\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "class BinaryOperator(object):\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "class Add(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        return self.a.evaluate() + self.b.evaluate()\n",
    "    def __str__(self):\n",
    "        return \"{} + {}\".format(self.a, self.b)\n",
    "\n",
    "class Mul(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        return self.a.evaluate() * self.b.evaluate()\n",
    "    def __str__(self):\n",
    "        return \"({}) * ({})\".format(self.a, self.b)\n",
    "\n",
    "x = Var(3, name=\"x\")\n",
    "y = Var(4, name=\"y\")\n",
    "f = Add(Mul(Mul(x, x), y), Add(y, Const(2))) # f(x,y) = x²y + y + 2\n",
    "print(\"f(x,y) =\", f)\n",
    "print(\"f(3,4) =\", f.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래디언트 계산\n",
    "### 수동 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dx(3,4) = 24\n",
      "df/dy(3,4) = 10\n"
     ]
    }
   ],
   "source": [
    "df_dx = Mul(Const(2), Mul(x, y))  # df/dx = 2xy\n",
    "df_dy = Add(Mul(x, x), Const(1))  # df/dy = x² + 1\n",
    "print(\"df/dx(3,4) =\", df_dx.evaluate())\n",
    "print(\"df/dy(3,4) =\", df_dy.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dx(3,4) = 24.000400000048216\n",
      "df/dy(3,4) = 10.000000000047748\n"
     ]
    }
   ],
   "source": [
    "def gradients(func, vars_list, eps=0.0001):\n",
    "    partial_derivatives = []\n",
    "    base_func_eval = func.evaluate()\n",
    "    for var in vars_list:\n",
    "        original_value = var.value\n",
    "        var.value = var.value + eps\n",
    "        tweaked_func_eval = func.evaluate()\n",
    "        var.value = original_value\n",
    "        derivative = (tweaked_func_eval - base_func_eval) / eps\n",
    "        partial_derivatives.append(derivative)\n",
    "    return partial_derivatives\n",
    "\n",
    "df_dx, df_dy = gradients(f, [x, y])\n",
    "print(\"df/dx(3,4) =\", df_dx)\n",
    "print(\"df/dy(3,4) =\", df_dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기호 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df/dx(3,4) = 24.0\n",
      "df/dy(3,4) = 10.0\n"
     ]
    }
   ],
   "source": [
    "Const.derive = lambda self, var: Const(0)\n",
    "Var.derive = lambda self, var: Const(1) if self is var else Const(0)\n",
    "Add.derive = lambda self, var: Add(self.a.derive(var), self.b.derive(var))\n",
    "Mul.derive = lambda self, var: Add(Mul(self.a, self.b.derive(var)), Mul(self.a.derive(var), self.b))\n",
    "\n",
    "x = Var(3.0, name=\"x\")\n",
    "y = Var(4.0, name=\"y\")\n",
    "f = Add(Mul(Mul(x, x), y), Add(y, Const(2))) # f(x,y) = x²y + y + 2\n",
    "\n",
    "df_dx = f.derive(x)  # 2xy\n",
    "df_dy = f.derive(y)  # x² + 1\n",
    "print(\"df/dx(3,4) =\", df_dx.evaluate())\n",
    "print(\"df/dy(3,4) =\", df_dy.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동 미분 (autodiff) – 전진 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualNumber(object):\n",
    "    def __init__(self, value=0.0, eps=0.0):\n",
    "        self.value = value\n",
    "        self.eps = eps\n",
    "    def __add__(self, b):\n",
    "        return DualNumber(self.value + self.to_dual(b).value,\n",
    "                          self.eps + self.to_dual(b).eps)\n",
    "    def __radd__(self, a):\n",
    "        return self.to_dual(a).__add__(self)\n",
    "    def __mul__(self, b):\n",
    "        return DualNumber(self.value * self.to_dual(b).value,\n",
    "                          self.eps * self.to_dual(b).value + self.value * self.to_dual(b).eps)\n",
    "    def __rmul__(self, a):\n",
    "        return self.to_dual(a).__mul__(self)\n",
    "    def __str__(self):\n",
    "        if self.eps:\n",
    "            return \"{:.1f} + {:.1f}ε\".format(self.value, self.eps)\n",
    "        else:\n",
    "            return \"{:.1f}\".format(self.value)\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    @classmethod\n",
    "    def to_dual(cls, n):\n",
    "        if hasattr(n, \"value\"):\n",
    "            return n\n",
    "        else:\n",
    "            return cls(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3 + (3 + 4 \\epsilon) = 6 + 4\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0 + 4.0ε"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 + DualNumber(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(3 + 4ε)\\times(5 + 7ε) = 3 \\times 5 + 3 \\times 7ε + 4ε \\times 5 + 4ε \\times 7ε = 15 + 21ε + 20ε + 28ε^2 = 15 + 41ε + 28 \\times 0 = 15 + 41ε$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0 + 41.0ε"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DualNumber(3, 4) * DualNumber(5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.value = DualNumber(3.0)\n",
    "y.value = DualNumber(4.0)\n",
    "\n",
    "f.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.value = DualNumber(3.0, 1.0)  # 3 + ε\n",
    "y.value = DualNumber(4.0)       # 4\n",
    "\n",
    "df_dx = f.evaluate().eps\n",
    "\n",
    "x.value = DualNumber(3.0)       # 3\n",
    "y.value = DualNumber(4.0, 1.0)  # 4 + ε\n",
    "\n",
    "df_dy = f.evaluate().eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동 미분 – 후진 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x,y) = ((x) * (x)) * (y) + y + 2\n",
      "f(3,4) = 42\n",
      "df_dx = 24.0\n",
      "df_dy = 10.0\n"
     ]
    }
   ],
   "source": [
    "class Const(object):\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def backpropagate(self, gradient):\n",
    "        pass\n",
    "    def __str__(self):\n",
    "        return str(self.value)\n",
    "\n",
    "class Var(object):\n",
    "    def __init__(self, init_value, name):\n",
    "        self.value = init_value\n",
    "        self.name = name\n",
    "        self.gradient = 0\n",
    "    def evaluate(self):\n",
    "        return self.value\n",
    "    def backpropagate(self, gradient):\n",
    "        self.gradient += gradient\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "class BinaryOperator(object):\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "class Add(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        self.value = self.a.evaluate() + self.b.evaluate()\n",
    "        return self.value\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient)\n",
    "        self.b.backpropagate(gradient)\n",
    "    def __str__(self):\n",
    "        return \"{} + {}\".format(self.a, self.b)\n",
    "\n",
    "class Mul(BinaryOperator):\n",
    "    def evaluate(self):\n",
    "        self.value = self.a.evaluate() * self.b.evaluate()\n",
    "        return self.value\n",
    "    def backpropagate(self, gradient):\n",
    "        self.a.backpropagate(gradient * self.b.value)\n",
    "        self.b.backpropagate(gradient * self.a.value)\n",
    "    def __str__(self):\n",
    "        return \"({}) * ({})\".format(self.a, self.b)\n",
    "\n",
    "x = Var(3, name=\"x\")\n",
    "y = Var(4, name=\"y\")\n",
    "f = Add(Mul(Mul(x, x), y), Add(y, Const(2))) # f(x,y) = x²y + y + 2\n",
    "\n",
    "result = f.evaluate()\n",
    "f.backpropagate(1.0)\n",
    "\n",
    "print(\"f(x,y) =\", f)\n",
    "print(\"f(3,4) =\", result)\n",
    "print(\"df_dx =\", x.gradient)\n",
    "print(\"df_dy =\", y.gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동 미분 – 후진 모드 (텐서플로를 사용해서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42.0, [24.0, 10.0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "x = tf.Variable(3., name=\"x\")\n",
    "y = tf.Variable(4., name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "\n",
    "gradients = tf.gradients(f, [x, y])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    f_val, gradients_val = sess.run([f, gradients])\n",
    "\n",
    "f_val, gradients_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 해답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "부록 A 참조."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 텐서플로를 사용한 미니배치 경사 하강법으로 구현한 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 사이킷런의 `make_moons()` 함수를 사용해 moons 데이터셋을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 잠깐 들여다 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1], 'go', label=\"Positive\")\n",
    "plt.plot(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 샘플에 추가적인 편향 특성($x_0 = 1$)을 추가해야 합니다. 이렇게 하려면 입력 행렬 $\\mathbf{X}$의 왼쪽에 1로 채워진 열을 추가해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_moons_with_bias = np.c_[np.ones((m, 1)), X_moons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.05146968,  0.44419863],\n",
       "       [ 1.        ,  1.03201691, -0.41974116],\n",
       "       [ 1.        ,  0.86789186, -0.25482711],\n",
       "       [ 1.        ,  0.288851  , -0.44866862],\n",
       "       [ 1.        , -0.83343911,  0.53505665]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_moons_with_bias[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋네요. 이제 `y_train`의 크기를 바꾸어 열 벡터로 만들겠습니다(즉, 하나의 열이 있는 2D 배열입니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_moons_column_vector = y_moons.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터셋을 훈련 세트와 테스트 세트로 나눕니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(m * test_ratio)\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋습니다. 이제 훈련 배치를 생성하기 위한 간단한 함수를 만들겠습니다. 이 함수는 각 배치를 위해 훈련 세트에서 랜덤하게 샘플을 선택합니다. 하나의 배치에 동일한 샘플이 여러번 들어갈 수 있고 한 번의 에포크에 모든 훈련 샘플이 포함되지 않을 수 있습니다(사실 샘플의 3분의 2 정도가 포함됩니다). 하지만 실전에서 별 문제가 되지 않고 코드가 간단해 집니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작은 배치 하나를 만들어 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.93189866,  0.13158788],\n",
       "       [ 1.        ,  1.07172763,  0.13482039],\n",
       "       [ 1.        , -1.01148674, -0.04686381],\n",
       "       [ 1.        ,  0.02201868,  0.19079139],\n",
       "       [ 1.        , -0.98941204,  0.02473116]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, y_batch = random_batch(X_train, y_train, 5)\n",
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋습니다! 모델에 주입할 데이터가 준비되었으므로 모델을 만들 차례입니다. 간단하게 시작해서 기능을 점차 추가해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저  기본 그래프를 리셋합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_moons_ 데이터셋은 두 개의 입력 특성을 가지므로 각 샘플은 평면 위의 한 점입니다(즉, 2차원입니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀 모델을 만들어 보겠습니다. 4장에서 보았던 것처럼 이 모델은 먼저 (선형 회귀 모델과 동일하게) 입력의 가중치 합을 계산하고 그 결과를 시그모이드 함수에 적용하여 양성 클래스에 대한 추정 확률을 만듭니다:\n",
    "\n",
    "$\\hat{p} = h_\\mathbf{\\theta}(\\mathbf{x}) = \\sigma(\\mathbf{\\theta}^T \\cdot \\mathbf{x})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{\\theta}$는 편향 $\\theta_0$와 가중치 $\\theta_1, \\theta_2, \\dots, \\theta_n$를 포함한 파라미터 벡터입니다. 입력 벡터 $\\mathbf{x}$는 상수 항 $x_0 = 1$과 입력 특성 $x_1, x_2, \\dots, x_n$을 포함합니다.\n",
    "\n",
    "한 번에 여러 샘플에 대한 예측을 만들 수 있어야 하므로 하나의 입력 벡터보다는 입력 행렬 $\\mathbf{X}$를 사용합니다. $i^{th}$ 번째 행이 $i^{th}$ 번째 입력 벡터의 전치$(\\mathbf{x}^{(i)})^T$입니다. 다음 식을 사용하여 각 샘플이 양성 클래스에 속할 확률을 추정할 수 있습니다:\n",
    "\n",
    "$ \\hat{\\mathbf{p}} = \\sigma(\\mathbf{X} \\cdot \\mathbf{\\theta})$\n",
    "\n",
    "모델을 만들기 위해 준비를 마쳤습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "logits = tf.matmul(X, theta, name=\"logits\")\n",
    "y_proba = 1 / (1 + tf.exp(-logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 텐서플로는 `tf.sigmoid()` 함수를 가지고 있어 마지막 라인을 다음과 같이 바꿀 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4장에서 보았듯이 로그 손실은 로지스틱 회귀에 사용하기 좋은 비용 함수입니다:\n",
    "\n",
    "$J(\\mathbf{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}$\n",
    "\n",
    "직접 구현하는 것도 한가지 방법입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-7  # 로그를 계산할 때 오버플로우를 피하기 위해\n",
    "loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + (1 - y) * tf.log(1 - y_proba + epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 텐서플로의 `tf.losses.log_loss()` 함수를 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.log_loss(y, y_proba)  # 기본적으로 epsilon = 1e-7 가 사용됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지는 아주 기본적입니다. 옵티마이저를 만들고 비용 함수를 최소화시키도록 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(이 간단한 예에서) 남은 것은 변수 초기화입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 훈련하고 예측을 만들 준비가 되었습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 코드에는 특별한 것은 없습니다. 앞서 선형 회귀에서 사용했던 것과 사실상 동일합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 0 \tLoss: 0.79260236\n",
      "에포크: 100 \tLoss: 0.3434635\n",
      "에포크: 200 \tLoss: 0.30754042\n",
      "에포크: 300 \tLoss: 0.29288897\n",
      "에포크: 400 \tLoss: 0.28533572\n",
      "에포크: 500 \tLoss: 0.2804781\n",
      "에포크: 600 \tLoss: 0.27808297\n",
      "에포크: 700 \tLoss: 0.27615443\n",
      "에포크: 800 \tLoss: 0.27551997\n",
      "에포크: 900 \tLoss: 0.27491236\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test, y: y_test})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"에포크:\", epoch, \"\\tLoss:\", loss_val)\n",
    "\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노트: 배치를 만들 때 에포크 수를 사용하지 않았으므로 두 개의 `for` 반복을 중첩하지 않고 하나의 `for` 반복을 사용할 수 있습니다. 하지만 훈련 시간을 에포크의 개수로 생각하는게 편리합니다(즉, 알고리즘이 훈련 세트를 모두 훑고 지나가는 횟수)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 세트에 있는 각 샘플에 대해서 `y_proba_val`은 해당 샘플이 양성 클래스에 속할 모델의 추정 확률을 담고 있습니다. 예를 들어 다음은 첫 번째 다섯 개 샘플의 추정 확률입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54895616],\n",
       "       [0.7072437 ],\n",
       "       [0.51900256],\n",
       "       [0.9911136 ],\n",
       "       [0.50859046]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_val[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 샘플을 분류하기 위해서 최대 가능도 방법(maximum likelihood)을 사용합니다. 추정 확률이 0.5보다 크거나 같으면 양성으로 분류합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_proba_val >= 0.5)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경우에 따라 0.5말고 다른 임계값을 사용해야 할 수 있습니다. 가령 높은 정밀도(대신 낮은 재현율)를 원한다면 임계값을 높이고 재현율을 높이려면(대신 낮은 정밀도) 임계값을 낮춥니다. 자세한 내용은 3장을 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 정밀도와 재현율을 계산해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627450980392157"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 예측이 어떻게 보이는지 그래프로 나타내 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # 열 벡터를 1차원 배열로 바꿉니다\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"양성\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"음성\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "음 결과가 좋지 않네요. 그렇죠? 하지만 로지스틱 회귀 모델은 선형적인 결정 경계를 가지므로 최선에 가까운 것 같습니다(잠시 후에 보겠지만 특성을 더 추가하지 않는다면 말이죠)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 시작해 보죠. 이번에는 연습문제에 나열된 모든 부가 기능을 추가해 보겠습니다:\n",
    "* 재사용이 용이하도록 `logistic_regression()` 함수 안에서 그래프를 정의합니다.\n",
    "* 훈련하는 동안 일정한 간격으로 `Saver` 객체를 사용해 체크포인트를 저장하고 훈련이 끝날 때 최종 모델을 저장합니다.\n",
    "* 훈련이 중지되고 다시 시작할 때 마지막 체크포인트를 복원합니다.\n",
    "* 텐서보드에서 그래프가 잘 정돈되어 보이도록 이름 범위를 사용하여 그래프를 정의합니다.\n",
    "* 서머리(summary)를 추가해 텐서보드에서 학습 곡선을 나타냅니다.\n",
    "* 학습률, 미니배치 크기 같은 하이퍼파라미터를 바꾸어 보면서 학습 곡선의 모양을 관찰합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작하기 전에 입력에 ${x_1}^2$, ${x_2}^2$, ${x_1}^3$ 그리고 ${x_2}^3$ 네 개의 특성을 추가합니다. 연습문제에 포함되어 있지는 않지만 특성을 추가하면 모델의 성능이 향상되는 것을 확인할 수 있습니다. 여기서는 수동으로 특성을 추가하지만 `sklearn.preprocessing.PolynomialFeatures`을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enhanced = np.c_[X_train,\n",
    "                         np.square(X_train[:, 1]),\n",
    "                         np.square(X_train[:, 2]),\n",
    "                         X_train[:, 1] ** 3,\n",
    "                         X_train[:, 2] ** 3]\n",
    "X_test_enhanced = np.c_[X_test,\n",
    "                        np.square(X_test[:, 1]),\n",
    "                        np.square(X_test[:, 2]),\n",
    "                        X_test[:, 1] ** 3,\n",
    "                        X_test[:, 2] ** 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성이 추가된 훈련 세트는 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -5.14696757e-02,  4.44198631e-01,\n",
       "         2.64912752e-03,  1.97312424e-01, -1.36349734e-04,\n",
       "         8.76459084e-02],\n",
       "       [ 1.00000000e+00,  1.03201691e+00, -4.19741157e-01,\n",
       "         1.06505890e+00,  1.76182639e-01,  1.09915879e+00,\n",
       "        -7.39511049e-02],\n",
       "       [ 1.00000000e+00,  8.67891864e-01, -2.54827114e-01,\n",
       "         7.53236288e-01,  6.49368582e-02,  6.53727646e-01,\n",
       "        -1.65476722e-02],\n",
       "       [ 1.00000000e+00,  2.88850997e-01, -4.48668621e-01,\n",
       "         8.34348982e-02,  2.01303531e-01,  2.41002535e-02,\n",
       "        -9.03185778e-02],\n",
       "       [ 1.00000000e+00, -8.33439108e-01,  5.35056649e-01,\n",
       "         6.94620746e-01,  2.86285618e-01, -5.78924095e-01,\n",
       "         1.53179024e-01]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enhanced[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋습니다. 이제 기본 그래프를 초기화합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 만들기 위해 `logistic_regression()` 함수를 정의합니다. 입력 `X`와 타깃 `y`의 정의를 포함하지 않았습니다. 이 함수에서 정의할 수도 있지만 그렇게 하지 않아야 다양한 경우에 이 함수를 사용할 수 있습니다(예를 들어, 로지스틱 회귀 모델에 주입하기 전에 입력에 대해 전처리 단계를 추가할 수 있습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, initializer=None, seed=42, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform([n_inputs_including_bias, 1], -1.0, 1.0, seed=seed)\n",
    "            theta = tf.Variable(initializer, name=\"theta\")\n",
    "            logits = tf.matmul(X, theta, name=\"logits\")\n",
    "            y_proba = tf.sigmoid(logits)\n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss = tf.losses.log_loss(y, y_proba, scope=\"loss\")\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "    return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드를 위해 서머리를 저장할 로그 디렉토리 이름을 생성하는 함수를 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `logistic_regression()` 함수를 사용해 그래프를 만듭니다. 텐서보드용 서머리를 로그 디렉토리에 저장하기 위해 `FileWriter`도 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2 + 4\n",
    "logdir = log_dir(\"logreg\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "드디어 모델을 학습시킬 수 있습니다! 이전에 훈련 세션이 중지되었는지부터 검사하고 그렇다면 체크포인트를 로드하고 저장된 에포크 횟수부터 훈련을 이어갑니다. 이 예에서는 별도의 파일에 에포트 횟수를 저장했지만 11장에서 모델에 일부로 훈련 스텝을저장하는 방법을 배우겠습니다. 예를 들어 `global_step`이란 훈련되지 않는 변수를 옵티마이저의 `minimize()` 메서드에 전달합니다.\n",
    "\n",
    "다시 시작할 때 마지막 체크포인트가 제대로 복원되는지 확인하기 위해 훈련을 중지시켜 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크: 0 \t손실: 0.62998503\n",
      "에포크: 500 \t손실: 0.16122366\n",
      "에포크: 1000 \t손실: 0.11903212\n",
      "에포크: 1500 \t손실: 0.097329214\n",
      "에포크: 2000 \t손실: 0.083697945\n",
      "에포크: 2500 \t손실: 0.07437584\n",
      "에포크: 3000 \t손실: 0.067502156\n",
      "에포크: 3500 \t손실: 0.06220691\n",
      "에포크: 4000 \t손실: 0.058026787\n",
      "에포크: 4500 \t손실: 0.05456298\n",
      "에포크: 5000 \t손실: 0.051708277\n",
      "에포크: 5500 \t손실: 0.04923773\n",
      "에포크: 6000 \t손실: 0.047167283\n",
      "에포크: 6500 \t손실: 0.045376636\n",
      "에포크: 7000 \t손실: 0.043818742\n",
      "에포크: 7500 \t손실: 0.042374216\n",
      "에포크: 8000 \t손실: 0.041089155\n",
      "에포크: 8500 \t손실: 0.039970912\n",
      "에포크: 9000 \t손실: 0.038920246\n",
      "에포크: 9500 \t손실: 0.038010743\n",
      "에포크: 10000 \t손실: 0.0371557\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_logreg_model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # 체크포인트 파일이 있으면 모델을 복원하고 에포크 횟수를 로드합니다\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"중지되었던 훈련입니다. 에포크를 이어갑니다.\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"에포크:\", epoch, \"\\t손실:\", loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "\n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서도 추정 확률이 0.5보다 크거나 같은 샘플을 모두 양성으로 분류하면 예측이 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_proba_val >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # 열 벡터 대신 1차원 배열\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"양성\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"음성\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훨씬 더 좋아졌네요! 새로 추가한 특성이 확실히 도움이 많이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드 서버를 시작해서 최근 실행을 찾아 학습 곡선을 확인해 보세요(즉, 에포크 횟수에 대해 테스트 세트로 평가한 손실이 얼마나 되는지):\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=tf_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 하이퍼파라미터(가령, `batch_size`나 `learning_rate`)를 조정하면서 훈련을 여러번 실행해 보고 학습 곡선을 비교해 보겠습니다. 그리드 서치나 랜덤 서치를 구현해서 이 과정을 자동화할 수도 있습니다. 다음은 배치 크기와 학습률에 대한 간단한 랜덤 서치 구현입니다. 간단하게 하기 위해서 체크포인트 관리 부분은 제외했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복 0\n",
      "  logdir: tf_logs/logreg-run-20180405072916/\n",
      "  batch_size: 54\n",
      "  learning_rate: 0.004430375245218265\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9797979797979798\n",
      "  재현율: 0.9797979797979798\n",
      "반복 1\n",
      "  logdir: tf_logs/logreg-run-20180405073454/\n",
      "  batch_size: 22\n",
      "  learning_rate: 0.0017826497151386947\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9797979797979798\n",
      "  재현율: 0.9797979797979798\n",
      "반복 2\n",
      "  logdir: tf_logs/logreg-run-20180405074502/\n",
      "  batch_size: 74\n",
      "  learning_rate: 0.00203228544324115\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9696969696969697\n",
      "  재현율: 0.9696969696969697\n",
      "반복 3\n",
      "  logdir: tf_logs/logreg-run-20180405074813/\n",
      "  batch_size: 58\n",
      "  learning_rate: 0.004491523825137997\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9797979797979798\n",
      "  재현율: 0.9797979797979798\n",
      "반복 4\n",
      "  logdir: tf_logs/logreg-run-20180405075337/\n",
      "  batch_size: 61\n",
      "  learning_rate: 0.07963234721775589\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9801980198019802\n",
      "  재현율: 1.0\n",
      "반복 5\n",
      "  logdir: tf_logs/logreg-run-20180405075839/\n",
      "  batch_size: 92\n",
      "  learning_rate: 0.0004634250583294876\n",
      "  훈련: .....................\n",
      "  정밀도: 0.912621359223301\n",
      "  재현율: 0.9494949494949495\n",
      "반복 6\n",
      "  logdir: tf_logs/logreg-run-20180405080056/\n",
      "  batch_size: 74\n",
      "  learning_rate: 0.047706818419354494\n",
      "  훈련: .....................\n",
      "  정밀도: 0.98\n",
      "  재현율: 0.98989898989899\n",
      "반복 7\n",
      "  logdir: tf_logs/logreg-run-20180405080512/\n",
      "  batch_size: 58\n",
      "  learning_rate: 0.0001694044709524274\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9\n",
      "  재현율: 0.9090909090909091\n",
      "반복 8\n",
      "  logdir: tf_logs/logreg-run-20180405080949/\n",
      "  batch_size: 61\n",
      "  learning_rate: 0.04171461199412461\n",
      "  훈련: .....................\n",
      "  정밀도: 0.9801980198019802\n",
      "  재현율: 1.0\n",
      "반복 9\n",
      "  logdir: tf_logs/logreg-run-20180405081343/\n",
      "  batch_size: 92\n",
      "  learning_rate: 0.00010742922968438615\n",
      "  훈련: .....................\n",
      "  정밀도: 0.8823529411764706\n",
      "  재현율: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "\n",
    "n_search_iterations = 10\n",
    "\n",
    "for search_iteration in range(n_search_iterations):\n",
    "    batch_size = np.random.randint(1, 100)\n",
    "    learning_rate = reciprocal(0.0001, 0.1).rvs(random_state=search_iteration)\n",
    "\n",
    "    n_inputs = 2 + 4\n",
    "    logdir = log_dir(\"logreg\")\n",
    "    \n",
    "    print(\"반복\", search_iteration)\n",
    "    print(\"  logdir:\", logdir)\n",
    "    print(\"  batch_size:\", batch_size)\n",
    "    print(\"  learning_rate:\", learning_rate)\n",
    "    print(\"  훈련: \", end=\"\")\n",
    "\n",
    "    reset_graph()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "    y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(\n",
    "        X, y, learning_rate=learning_rate)\n",
    "\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "    n_epochs = 10001\n",
    "    n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "    final_model_path = \"./my_logreg_model_%d\" % search_iteration\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_index in range(n_batches):\n",
    "                X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "            if epoch % 500 == 0:\n",
    "                print(\".\", end=\"\")\n",
    "\n",
    "        saver.save(sess, final_model_path)\n",
    "\n",
    "        print()\n",
    "        y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
    "        y_pred = (y_proba_val >= 0.5)\n",
    "        \n",
    "        print(\"  정밀도:\", precision_score(y_test, y_pred))\n",
    "        print(\"  재현율:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하이퍼파라미터의 적절한 스케일을 감잡을 수 없을 때 사이파이(SciPy)의 `stats` 모듈의 `reciprocal()` 함수를 사용하여 난수 분포를 얻을 수 있습니다. 좀 더 자세한 내용은 2장의 연습문제 해답을 보세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "nav_menu": {
   "height": "603px",
   "width": "616px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
